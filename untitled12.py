# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GqQwQI82cK1JHkYSLMzRiAbEvnKjFqCt
"""

#!/usr/bin/env python3
#
# Compute Sobel gradient to images (pytorch)

import numpy as np
import matplotlib.pyplot as plt

# We use torch for this example and use example images from torchvision
# Install these packages with `pip3 install torch torch vision` or similar
import torch as t
import torchvision as tv

# Load example dataset (actually for machine learning, but works for this, too)
transf = tv.transforms.Compose([tv.transforms.Grayscale(), tv.transforms.ToTensor()])
imgset = tv.datasets.CIFAR10(root='./cifar10-data', train=True,
                             download=True, transform=transf)
imgloader = t.utils.data.DataLoader(imgset, batch_size=16,
                                    shuffle=True, num_workers=2)
# Get 16 (given by batch_size above) random (as we shuffle) images
dataiter = iter(imgloader)
images, _ = next(dataiter) # Two outputs, as this is an input/output pair for machine learning

# Sobel gradient:
# Convolution with Sobel filter
#     [[-1,0,1]
#      [-2,0,2]
#      [-1,0,1]]
# in x and y direction.
# Then take norm of x/y value per pixel.

# Sobel filter (in x; y is transposed)
sobel_x = t.autograd.Variable(t.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]]))
# Turn from 3x3 into 1x1x3x3 tensor
sobel_x.unsqueeze_(0).unsqueeze_(0)

# Apply convolution for x and y direction
g_x = t.nn.functional.conv2d(images,sobel_x)
g_y = t.nn.functional.conv2d(images,sobel_x.transpose(2,3))
# Compute norm
g = t.sqrt(t.pow(g_x,2)+t.pow(g_y,2))

# Show images and results
fig, ax = plt.subplots(4, 1, figsize=(8,8))
def imshow(imgs,ax):
    ax.imshow(np.transpose(tv.utils.make_grid(imgs).numpy(), (1, 2, 0)), cmap='gray', vmin=0, vmax=1)
imshow(images,ax[0])
imshow(g_x,ax[1])
imshow(g_y,ax[2])
imshow(g,ax[3])
plt.show()

#!/usr/bin/env python3
#
# Simple CNN example to classify images from the Fashion-MNIST dataset
# (as part of keras.dataset examples); see https://keras.io/
# This uses tensorflow: https://www.tensorflow.org/api_docs/python/tf

import numpy as np
import matplotlib.pyplot as plt

# Use tensorflow's keras (needs tensorflow or other supported backend; GPU version highly recommended)
# Install tensorflow with `pipe3 install tensorflow` or similar
import tensorflow.keras as k

# Get the dataset, split in training and test set
# x is the image, y the classification
(train_x,train_y), (test_x,test_y) = k.datasets.fashion_mnist.load_data()

# Convert iamges to float and noramlise image grayscale values to 0...1
train_x = train_x.astype('float32')
test_x = test_x.astype('float32')
train_x = train_x / 255.0
test_x = test_x / 255.0

# Reshape Nx28x28 images to Nx28x28x1 tensor for N images
# (last index is channel; only one as grayscale)
train_x = train_x.reshape(-1, 28,28, 1)
test_x = test_x.reshape(-1, 28,28, 1)

# Y data in the dataset is a label from 0...9:
# Label Description  Category
# 0     T-shirt/top  0000000001
# 1     Trouser      0000000010
# 2     Pullover     0000000100
# 3     Dress        0000001000
# 4     Coat         0000010000
# 5     Sandal       0000100000
# 6     Shirt        0001000000
# 7     Sneaker      0010000000
# 8     Bag          0100000000
# 9     Ankle boot   1000000000
# We cannot use this directly for classification, but must convert it to
# a bit string, where each bit represents one class, as indicated in the
# lat column, i.e. convert it to a categorical representation.
#
train_y = k.utils.to_categorical(train_y)
test_y = k.utils.to_categorical(test_y)

# We use a sequential (simple layered) model for the CNN
model = k.models.Sequential()

# First convolutional block with 64 filters, max-pool and batch normalisation
model.add(k.layers.Conv2D(32, (3,3), activation="relu", input_shape=(28, 28, 1)))
model.add(k.layers.Conv2D(32, (3,3), activation="relu"))
model.add(k.layers.MaxPooling2D(pool_size=(2,2)))
model.add(k.layers.BatchNormalization())

# Second convolutional block with 128 filters
model.add(k.layers.Conv2D(64, (3,3), activation="relu"))
model.add(k.layers.Conv2D(64, (3,3), activation="relu"))
model.add(k.layers.MaxPooling2D(pool_size=(2,2)))
model.add(k.layers.BatchNormalization())

# Third convolutional block with 256 filters, only one convolution layer
model.add(k.layers.Conv2D(128, (3,3), activation="relu"))
model.add(k.layers.MaxPooling2D(pool_size=(2,2)))
model.add(k.layers.BatchNormalization())

# Flatten output (map to vector) for fully connected layer on that vector
model.add(k.layers.Flatten())
model.add(k.layers.Dense(256))

# Map 64 vector to 10 vector and use softmax for probabilities input is of specific category
model.add(k.layers.Dense(10, activation="softmax"))

# Create and fit model using cross-entropy loss
epochs = 10 # 10 epochs for testing; try 50 for better results
model.compile(loss=k.losses.categorical_crossentropy,
              optimizer=k.optimizers.Adam(), metrics=['accuracy'])
# Save figure of model
k.utils.plot_model(model, to_file=("lab2-1-cnn-tensorflow.png"), show_shapes=True,
                   show_dtype=True, show_layer_names=True, show_layer_activations=True,
                   rankdir='TB', expand_nested=True, dpi=96)
h = model.fit(train_x, train_y, batch_size=64, epochs=epochs,
              validation_data=(test_x, test_y))

# Evaluate model on test set
test_loss, test_acc = model.evaluate(test_x, test_y)
print('Test loss', test_loss)
print('Test accuracy', test_acc)

# Plot training history for training and validation accuracy
fig, ax = plt.subplots(2, 1, figsize=(8,8))
ax[0].plot(h.history['accuracy'])
ax[0].plot(h.history['val_accuracy'])
ax[0].set_title('Model Accuracy')
ax[0].set_ylabel('Accuracy')
ax[0].set_xlabel('Epoch')
ax[0].legend(['train', 'test'], loc='upper left')

# Run prediction, report result for first image and show that image
pred_y = model.predict(test_x[0:1,...])
print("Predicted class:", np.argmax(pred_y[0]), ", ground truth: ", np.argmax(test_y[0]))
ax[1].imshow(test_x[0], cmap="gray")
plt.show()

# Run prediction for the first six images and report results
pred_y_first_six = model.predict(test_x[0:6,...])

# Report results for the first six images
for i in range(6):
    print("Prediction for the {}th image:".format(i + 1))
    print("Predicted class:", np.argmax(pred_y_first_six[i]), ", ground truth: ", np.argmax(test_y[i]))
    print()

# Show the first six images
fig, axes = plt.subplots(2, 3, figsize=(10, 6))
for i, ax in enumerate(axes.flat):
    ax.imshow(test_x[i], cmap="gray")
    ax.set_title("Image {}".format(i + 1))
plt.tight_layout()
plt.show()

#!/usr/bin/env python3
#
# Compute Sobel gradient to images (tensorflow)

import numpy as np
import matplotlib.pyplot as plt

# We use tensorflow: install this with `pip3 install tensorflow` or similar
import tensorflow as tf

# Load example dataset (actually for machine learning, but works for this, too)
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
# We only want 16 random example images
images = x_train[np.random.randint(x_train.shape[0], size=16),...] # 16x32x32x3 tensor
# Turn into greyscale
images = tf.image.rgb_to_grayscale(images) # 16x32x32x1 tensor
# Normalise to 0..1
images = tf.cast(images, tf.float32) / 255.0

# Sobel gradient:


blur = tf.constant([
            [ 1, 4, 6, 4, 1],
            [ 4,16,24,16, 4],
            [ 6,24,36,24, 6],
            [ 4,16,24,16, 4],
            [ 1, 4, 6, 4, 1]
                      ],
                       tf.float32)/256.0

# Sharpen
# Sharpen 
sharpen = tf.constant([
                [ 0,-1, 0],
                [-1, 5,-1],
                [ 0,-1, 0]
                       ],
                       tf.float32)

# Turn from 3x3 into 1x1x3x3 (height,width,inp_chs,out_chs) filter
sobel_x = tf.reshape(sharpen, [3, 3, 1, 1])
# Sobel y filter
sobel_y = tf.transpose(sobel_x, [1, 0, 2, 3])

# Apply convolution for x and y direction
# 
g_x = tf.nn.conv2d(images, sobel_x, strides=[1, 1, 1, 1], padding='SAME')
g_y = tf.nn.conv2d(images, sobel_y, strides=[1, 1, 1, 1], padding='SAME')
# Compute norm
g = tf.math.sqrt(tf.math.pow(g_x,2)+tf.math.pow(g_y,2))


# Show images and results
fig, ax = plt.subplots(4, 1, figsize=(8,8))
def imshow(imgs,ax,cmap):
  # Create a list of 16 entries of shape 32x32x1
  t = tf.unstack(imgs[:8 * 2], num=16, axis=0)
  # Concatenate 8 elements of the list to a row for two rows
  rows = [tf.concat(t[l*8:(l+1)*8], axis=1) for l in range(0,2)]
  # Concatenate the two rows
  image = tf.concat(rows, axis=0)
  ax.imshow(image, cmap=cmap, vmin=0, vmax=1)
imshow(images,ax[0],cmap="gray")
imshow(g_x,ax[1],cmap="viridis")
imshow(g_y,ax[2],cmap="viridis")
imshow(g,ax[3],cmap="viridis")
plt.show()





